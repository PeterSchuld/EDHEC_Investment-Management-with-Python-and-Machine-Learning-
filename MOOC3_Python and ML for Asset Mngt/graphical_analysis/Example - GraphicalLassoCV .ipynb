{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphicalLassoCV Example\n",
    "\n",
    "Last Update: July 22nd, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.covariance import GraphicalLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define true covariance matrix\n",
    "true_cov = np.array([[0.8, 0.0, 0.2, 0.0],\n",
    "                     [0.0, 0.4, 0.0, 0.0],\n",
    "                     [0.2, 0.0, 0.3, 0.1],\n",
    "                     [0.0, 0.0, 0.1, 0.7]])\n",
    "\n",
    "# Set seed and generate X from multivaraite norm with specified covariance\n",
    "np.random.seed(0)\n",
    "X = np.random.multivariate_normal(mean=[0, 0, 0, 0], cov=true_cov, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51515152,  0.        , -1.06060606,  0.15151515],\n",
       "       [ 0.        ,  2.5       ,  0.        ,  0.        ],\n",
       "       [-1.06060606,  0.        ,  4.24242424, -0.60606061],\n",
       "       [ 0.15151515,  0.        , -0.60606061,  1.51515152]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True precision matrix calculated from the inverse of true covariance matrix\n",
    "true_prec = np.linalg.inv(true_cov)\n",
    "true_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GraphicalLassoCV model\n",
    "est = GraphicalLassoCV(max_iter = 1000).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.816, 0.051, 0.22 , 0.017],\n",
       "       [0.051, 0.364, 0.018, 0.036],\n",
       "       [0.22 , 0.018, 0.322, 0.094],\n",
       "       [0.017, 0.036, 0.094, 0.69 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The estimated covariance matrix from GraphicalLassoCV\n",
    "np.around(est.covariance_, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.521, -0.17 , -1.063,  0.116],\n",
       "       [-0.17 ,  2.784, -0.   , -0.14 ],\n",
       "       [-1.063, -0.   ,  3.982, -0.518],\n",
       "       [ 0.116, -0.14 , -0.518,  1.524]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The estimated precision matrix from GraphicalLassoCV\n",
    "np.around(est.precision_, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22813020648178522,\n",
       " 0.049149163068849436,\n",
       " 0.026598029308124188,\n",
       " 0.014394042927746526,\n",
       " 0.010588866190156311,\n",
       " 0.008807435274025985,\n",
       " 0.008488861740795783,\n",
       " 0.008181811323310077,\n",
       " 0.007885867219221498,\n",
       " 0.007789617396298063,\n",
       " 0.007600627702330532,\n",
       " 0.007325705577266539,\n",
       " 0.006093256496935091,\n",
       " 0.005068150002186581,\n",
       " 0.00421550355833272,\n",
       " 0.0022813020648178514,\n",
       " 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of lambdas used in cross validation\n",
    "est.cv_alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008181811323310077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lambda chosen by cross validation\n",
    "est.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index of the chosen lambda in the list of lambdas\n",
    "ind_lambda = np.where(est.cv_alphas_ == est.alpha_)[0][0]\n",
    "ind_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.505, -4.166, -4.24 , -4.235, -4.238],\n",
       "       [-4.314, -4.045, -4.167, -4.174, -4.165],\n",
       "       [-4.281, -4.037, -4.161, -4.175, -4.171],\n",
       "       [-4.263, -4.033, -4.162, -4.174, -4.178],\n",
       "       [-4.257, -4.03 , -4.163, -4.175, -4.181],\n",
       "       [-4.254, -4.028, -4.163, -4.176, -4.183],\n",
       "       [-4.254, -4.028, -4.164, -4.176, -4.183],\n",
       "       [-4.253, -4.028, -4.164, -4.176, -4.183],\n",
       "       [-4.253, -4.027, -4.164, -4.176, -4.184],\n",
       "       [-4.252, -4.027, -4.164, -4.176, -4.184],\n",
       "       [-4.252, -4.027, -4.165, -4.176, -4.184],\n",
       "       [-4.252, -4.027, -4.165, -4.176, -4.184],\n",
       "       [-4.25 , -4.026, -4.167, -4.178, -4.186],\n",
       "       [-4.248, -4.025, -4.169, -4.18 , -4.187],\n",
       "       [-4.247, -4.025, -4.171, -4.181, -4.188],\n",
       "       [-4.244, -4.023, -4.174, -4.184, -4.19 ],\n",
       "       [-4.395, -4.038, -4.195, -4.209, -4.416]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid_scores_ndarray of shape (n_alphas, n_folds): Log-likelihood score on left-out data across folds.\n",
    "np.round(est.grid_scores_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambdas</th>\n",
       "      <th>score_fold1</th>\n",
       "      <th>score_fold2</th>\n",
       "      <th>score_fold3</th>\n",
       "      <th>score_fold4</th>\n",
       "      <th>score_fold5</th>\n",
       "      <th>Total_score</th>\n",
       "      <th>Average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228130</td>\n",
       "      <td>-4.504907</td>\n",
       "      <td>-4.165553</td>\n",
       "      <td>-4.239870</td>\n",
       "      <td>-4.234588</td>\n",
       "      <td>-4.237572</td>\n",
       "      <td>-21.382489</td>\n",
       "      <td>-4.276498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049149</td>\n",
       "      <td>-4.314145</td>\n",
       "      <td>-4.044966</td>\n",
       "      <td>-4.167367</td>\n",
       "      <td>-4.174215</td>\n",
       "      <td>-4.164886</td>\n",
       "      <td>-20.865579</td>\n",
       "      <td>-4.173116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026598</td>\n",
       "      <td>-4.280548</td>\n",
       "      <td>-4.037276</td>\n",
       "      <td>-4.161012</td>\n",
       "      <td>-4.175371</td>\n",
       "      <td>-4.170713</td>\n",
       "      <td>-20.824920</td>\n",
       "      <td>-4.164984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014394</td>\n",
       "      <td>-4.263416</td>\n",
       "      <td>-4.032820</td>\n",
       "      <td>-4.161703</td>\n",
       "      <td>-4.174424</td>\n",
       "      <td>-4.177955</td>\n",
       "      <td>-20.810318</td>\n",
       "      <td>-4.162064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010589</td>\n",
       "      <td>-4.256945</td>\n",
       "      <td>-4.029620</td>\n",
       "      <td>-4.162758</td>\n",
       "      <td>-4.175143</td>\n",
       "      <td>-4.181156</td>\n",
       "      <td>-20.805621</td>\n",
       "      <td>-4.161124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008807</td>\n",
       "      <td>-4.254074</td>\n",
       "      <td>-4.028186</td>\n",
       "      <td>-4.163405</td>\n",
       "      <td>-4.175665</td>\n",
       "      <td>-4.182822</td>\n",
       "      <td>-20.804152</td>\n",
       "      <td>-4.160830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008489</td>\n",
       "      <td>-4.253571</td>\n",
       "      <td>-4.027934</td>\n",
       "      <td>-4.163531</td>\n",
       "      <td>-4.175771</td>\n",
       "      <td>-4.183131</td>\n",
       "      <td>-20.803939</td>\n",
       "      <td>-4.160788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008182</td>\n",
       "      <td>-4.253089</td>\n",
       "      <td>-4.027693</td>\n",
       "      <td>-4.163656</td>\n",
       "      <td>-4.175877</td>\n",
       "      <td>-4.183434</td>\n",
       "      <td>-20.803749</td>\n",
       "      <td>-4.160750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007886</td>\n",
       "      <td>-4.252628</td>\n",
       "      <td>-4.027461</td>\n",
       "      <td>-4.164057</td>\n",
       "      <td>-4.175983</td>\n",
       "      <td>-4.183728</td>\n",
       "      <td>-20.803858</td>\n",
       "      <td>-4.160772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007790</td>\n",
       "      <td>-4.252478</td>\n",
       "      <td>-4.027386</td>\n",
       "      <td>-4.164211</td>\n",
       "      <td>-4.176019</td>\n",
       "      <td>-4.183823</td>\n",
       "      <td>-20.803917</td>\n",
       "      <td>-4.160783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007601</td>\n",
       "      <td>-4.252186</td>\n",
       "      <td>-4.027239</td>\n",
       "      <td>-4.164515</td>\n",
       "      <td>-4.176089</td>\n",
       "      <td>-4.184014</td>\n",
       "      <td>-20.804043</td>\n",
       "      <td>-4.160809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007326</td>\n",
       "      <td>-4.251763</td>\n",
       "      <td>-4.027026</td>\n",
       "      <td>-4.164964</td>\n",
       "      <td>-4.176299</td>\n",
       "      <td>-4.184292</td>\n",
       "      <td>-20.804344</td>\n",
       "      <td>-4.160869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006093</td>\n",
       "      <td>-4.249896</td>\n",
       "      <td>-4.026083</td>\n",
       "      <td>-4.167059</td>\n",
       "      <td>-4.178038</td>\n",
       "      <td>-4.185575</td>\n",
       "      <td>-20.806651</td>\n",
       "      <td>-4.161330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005068</td>\n",
       "      <td>-4.248381</td>\n",
       "      <td>-4.025315</td>\n",
       "      <td>-4.168910</td>\n",
       "      <td>-4.179585</td>\n",
       "      <td>-4.186685</td>\n",
       "      <td>-20.808876</td>\n",
       "      <td>-4.161775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004216</td>\n",
       "      <td>-4.247147</td>\n",
       "      <td>-4.024688</td>\n",
       "      <td>-4.170529</td>\n",
       "      <td>-4.180942</td>\n",
       "      <td>-4.187637</td>\n",
       "      <td>-20.810943</td>\n",
       "      <td>-4.162189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>-4.244440</td>\n",
       "      <td>-4.023257</td>\n",
       "      <td>-4.174477</td>\n",
       "      <td>-4.184273</td>\n",
       "      <td>-4.189901</td>\n",
       "      <td>-20.816348</td>\n",
       "      <td>-4.163270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.395458</td>\n",
       "      <td>-4.038115</td>\n",
       "      <td>-4.194629</td>\n",
       "      <td>-4.209178</td>\n",
       "      <td>-4.416023</td>\n",
       "      <td>-21.253404</td>\n",
       "      <td>-4.250681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lambdas  score_fold1  score_fold2  score_fold3  score_fold4  score_fold5  \\\n",
       "0   0.228130    -4.504907    -4.165553    -4.239870    -4.234588    -4.237572   \n",
       "1   0.049149    -4.314145    -4.044966    -4.167367    -4.174215    -4.164886   \n",
       "2   0.026598    -4.280548    -4.037276    -4.161012    -4.175371    -4.170713   \n",
       "3   0.014394    -4.263416    -4.032820    -4.161703    -4.174424    -4.177955   \n",
       "4   0.010589    -4.256945    -4.029620    -4.162758    -4.175143    -4.181156   \n",
       "5   0.008807    -4.254074    -4.028186    -4.163405    -4.175665    -4.182822   \n",
       "6   0.008489    -4.253571    -4.027934    -4.163531    -4.175771    -4.183131   \n",
       "7   0.008182    -4.253089    -4.027693    -4.163656    -4.175877    -4.183434   \n",
       "8   0.007886    -4.252628    -4.027461    -4.164057    -4.175983    -4.183728   \n",
       "9   0.007790    -4.252478    -4.027386    -4.164211    -4.176019    -4.183823   \n",
       "10  0.007601    -4.252186    -4.027239    -4.164515    -4.176089    -4.184014   \n",
       "11  0.007326    -4.251763    -4.027026    -4.164964    -4.176299    -4.184292   \n",
       "12  0.006093    -4.249896    -4.026083    -4.167059    -4.178038    -4.185575   \n",
       "13  0.005068    -4.248381    -4.025315    -4.168910    -4.179585    -4.186685   \n",
       "14  0.004216    -4.247147    -4.024688    -4.170529    -4.180942    -4.187637   \n",
       "15  0.002281    -4.244440    -4.023257    -4.174477    -4.184273    -4.189901   \n",
       "16  0.000000    -4.395458    -4.038115    -4.194629    -4.209178    -4.416023   \n",
       "\n",
       "    Total_score  Average_score  \n",
       "0    -21.382489      -4.276498  \n",
       "1    -20.865579      -4.173116  \n",
       "2    -20.824920      -4.164984  \n",
       "3    -20.810318      -4.162064  \n",
       "4    -20.805621      -4.161124  \n",
       "5    -20.804152      -4.160830  \n",
       "6    -20.803939      -4.160788  \n",
       "7    -20.803749      -4.160750  \n",
       "8    -20.803858      -4.160772  \n",
       "9    -20.803917      -4.160783  \n",
       "10   -20.804043      -4.160809  \n",
       "11   -20.804344      -4.160869  \n",
       "12   -20.806651      -4.161330  \n",
       "13   -20.808876      -4.161775  \n",
       "14   -20.810943      -4.162189  \n",
       "15   -20.816348      -4.163270  \n",
       "16   -21.253404      -4.250681  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary information \n",
    "alphas = np.array(est.cv_alphas_).reshape(len(est.cv_alphas_),1)\n",
    "df_temp = pd.DataFrame(np.concatenate((alphas,est.grid_scores_),axis = 1),\n",
    "                       columns = ['lambdas','score_fold1','score_fold2','score_fold3','score_fold4','score_fold5'])\n",
    "df_temp['Total_score'] = est.grid_scores_.sum(axis = 1)\n",
    "df_temp['Average_score'] = est.grid_scores_.sum(axis = 1)/est.grid_scores_.shape[1]\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda =  0.22813020648178522\n",
      "Number of zero entries in the precision matrix is :  12\n",
      "For lambda =  0.049149163068849436\n",
      "Number of zero entries in the precision matrix is :  6\n",
      "For lambda =  0.026598029308124188\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.014394042927746526\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.010588866190156311\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.008807435274025985\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.008488861740795783\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.008181811323310077\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.007885867219221498\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.007789617396298063\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.007600627702330532\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.007325705577266539\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.006093256496935091\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.005068150002186581\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.00421550355833272\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0.0022813020648178514\n",
      "Number of zero entries in the precision matrix is :  2\n",
      "For lambda =  0\n",
      "Number of zero entries in the precision matrix is :  0\n"
     ]
    }
   ],
   "source": [
    "# Find the precision matrix and number of zero entries in the matrix for each lambda\n",
    "prec_mx_list = []\n",
    "num_zeros_list = []\n",
    "\n",
    "for i in range(len(est.cv_alphas_)):\n",
    "    est_lambda = GraphicalLasso(alpha = est.cv_alphas_[i], max_iter = 1000).fit(X)\n",
    "    prec_mx_list.append(est_lambda.precision_)\n",
    "    \n",
    "    non_zero = (np.abs(est_lambda.precision_) > 0.02)\n",
    "    num_zeros = non_zero.shape[0] * non_zero.shape[1] - np.sum(non_zero*1)\n",
    "    num_zeros_list.append(num_zeros)\n",
    "    \n",
    "    print('For lambda = ', est.cv_alphas_[i])\n",
    "    print('Number of zero entries in the precision matrix is : ', num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambdas</th>\n",
       "      <th>score_fold1</th>\n",
       "      <th>score_fold2</th>\n",
       "      <th>score_fold3</th>\n",
       "      <th>score_fold4</th>\n",
       "      <th>score_fold5</th>\n",
       "      <th>Total_score</th>\n",
       "      <th>Average_score</th>\n",
       "      <th>Num_Zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.228130</td>\n",
       "      <td>-4.504907</td>\n",
       "      <td>-4.165553</td>\n",
       "      <td>-4.239870</td>\n",
       "      <td>-4.234588</td>\n",
       "      <td>-4.237572</td>\n",
       "      <td>-21.382489</td>\n",
       "      <td>-4.276498</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049149</td>\n",
       "      <td>-4.314145</td>\n",
       "      <td>-4.044966</td>\n",
       "      <td>-4.167367</td>\n",
       "      <td>-4.174215</td>\n",
       "      <td>-4.164886</td>\n",
       "      <td>-20.865579</td>\n",
       "      <td>-4.173116</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026598</td>\n",
       "      <td>-4.280548</td>\n",
       "      <td>-4.037276</td>\n",
       "      <td>-4.161012</td>\n",
       "      <td>-4.175371</td>\n",
       "      <td>-4.170713</td>\n",
       "      <td>-20.824920</td>\n",
       "      <td>-4.164984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014394</td>\n",
       "      <td>-4.263416</td>\n",
       "      <td>-4.032820</td>\n",
       "      <td>-4.161703</td>\n",
       "      <td>-4.174424</td>\n",
       "      <td>-4.177955</td>\n",
       "      <td>-20.810318</td>\n",
       "      <td>-4.162064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010589</td>\n",
       "      <td>-4.256945</td>\n",
       "      <td>-4.029620</td>\n",
       "      <td>-4.162758</td>\n",
       "      <td>-4.175143</td>\n",
       "      <td>-4.181156</td>\n",
       "      <td>-20.805621</td>\n",
       "      <td>-4.161124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008807</td>\n",
       "      <td>-4.254074</td>\n",
       "      <td>-4.028186</td>\n",
       "      <td>-4.163405</td>\n",
       "      <td>-4.175665</td>\n",
       "      <td>-4.182822</td>\n",
       "      <td>-20.804152</td>\n",
       "      <td>-4.160830</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008489</td>\n",
       "      <td>-4.253571</td>\n",
       "      <td>-4.027934</td>\n",
       "      <td>-4.163531</td>\n",
       "      <td>-4.175771</td>\n",
       "      <td>-4.183131</td>\n",
       "      <td>-20.803939</td>\n",
       "      <td>-4.160788</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008182</td>\n",
       "      <td>-4.253089</td>\n",
       "      <td>-4.027693</td>\n",
       "      <td>-4.163656</td>\n",
       "      <td>-4.175877</td>\n",
       "      <td>-4.183434</td>\n",
       "      <td>-20.803749</td>\n",
       "      <td>-4.160750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007886</td>\n",
       "      <td>-4.252628</td>\n",
       "      <td>-4.027461</td>\n",
       "      <td>-4.164057</td>\n",
       "      <td>-4.175983</td>\n",
       "      <td>-4.183728</td>\n",
       "      <td>-20.803858</td>\n",
       "      <td>-4.160772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007790</td>\n",
       "      <td>-4.252478</td>\n",
       "      <td>-4.027386</td>\n",
       "      <td>-4.164211</td>\n",
       "      <td>-4.176019</td>\n",
       "      <td>-4.183823</td>\n",
       "      <td>-20.803917</td>\n",
       "      <td>-4.160783</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.007601</td>\n",
       "      <td>-4.252186</td>\n",
       "      <td>-4.027239</td>\n",
       "      <td>-4.164515</td>\n",
       "      <td>-4.176089</td>\n",
       "      <td>-4.184014</td>\n",
       "      <td>-20.804043</td>\n",
       "      <td>-4.160809</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007326</td>\n",
       "      <td>-4.251763</td>\n",
       "      <td>-4.027026</td>\n",
       "      <td>-4.164964</td>\n",
       "      <td>-4.176299</td>\n",
       "      <td>-4.184292</td>\n",
       "      <td>-20.804344</td>\n",
       "      <td>-4.160869</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006093</td>\n",
       "      <td>-4.249896</td>\n",
       "      <td>-4.026083</td>\n",
       "      <td>-4.167059</td>\n",
       "      <td>-4.178038</td>\n",
       "      <td>-4.185575</td>\n",
       "      <td>-20.806651</td>\n",
       "      <td>-4.161330</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005068</td>\n",
       "      <td>-4.248381</td>\n",
       "      <td>-4.025315</td>\n",
       "      <td>-4.168910</td>\n",
       "      <td>-4.179585</td>\n",
       "      <td>-4.186685</td>\n",
       "      <td>-20.808876</td>\n",
       "      <td>-4.161775</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004216</td>\n",
       "      <td>-4.247147</td>\n",
       "      <td>-4.024688</td>\n",
       "      <td>-4.170529</td>\n",
       "      <td>-4.180942</td>\n",
       "      <td>-4.187637</td>\n",
       "      <td>-20.810943</td>\n",
       "      <td>-4.162189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>-4.244440</td>\n",
       "      <td>-4.023257</td>\n",
       "      <td>-4.174477</td>\n",
       "      <td>-4.184273</td>\n",
       "      <td>-4.189901</td>\n",
       "      <td>-20.816348</td>\n",
       "      <td>-4.163270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.395458</td>\n",
       "      <td>-4.038115</td>\n",
       "      <td>-4.194629</td>\n",
       "      <td>-4.209178</td>\n",
       "      <td>-4.416023</td>\n",
       "      <td>-21.253404</td>\n",
       "      <td>-4.250681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lambdas  score_fold1  score_fold2  score_fold3  score_fold4  score_fold5  \\\n",
       "0   0.228130    -4.504907    -4.165553    -4.239870    -4.234588    -4.237572   \n",
       "1   0.049149    -4.314145    -4.044966    -4.167367    -4.174215    -4.164886   \n",
       "2   0.026598    -4.280548    -4.037276    -4.161012    -4.175371    -4.170713   \n",
       "3   0.014394    -4.263416    -4.032820    -4.161703    -4.174424    -4.177955   \n",
       "4   0.010589    -4.256945    -4.029620    -4.162758    -4.175143    -4.181156   \n",
       "5   0.008807    -4.254074    -4.028186    -4.163405    -4.175665    -4.182822   \n",
       "6   0.008489    -4.253571    -4.027934    -4.163531    -4.175771    -4.183131   \n",
       "7   0.008182    -4.253089    -4.027693    -4.163656    -4.175877    -4.183434   \n",
       "8   0.007886    -4.252628    -4.027461    -4.164057    -4.175983    -4.183728   \n",
       "9   0.007790    -4.252478    -4.027386    -4.164211    -4.176019    -4.183823   \n",
       "10  0.007601    -4.252186    -4.027239    -4.164515    -4.176089    -4.184014   \n",
       "11  0.007326    -4.251763    -4.027026    -4.164964    -4.176299    -4.184292   \n",
       "12  0.006093    -4.249896    -4.026083    -4.167059    -4.178038    -4.185575   \n",
       "13  0.005068    -4.248381    -4.025315    -4.168910    -4.179585    -4.186685   \n",
       "14  0.004216    -4.247147    -4.024688    -4.170529    -4.180942    -4.187637   \n",
       "15  0.002281    -4.244440    -4.023257    -4.174477    -4.184273    -4.189901   \n",
       "16  0.000000    -4.395458    -4.038115    -4.194629    -4.209178    -4.416023   \n",
       "\n",
       "    Total_score  Average_score  Num_Zeros  \n",
       "0    -21.382489      -4.276498         12  \n",
       "1    -20.865579      -4.173116          6  \n",
       "2    -20.824920      -4.164984          2  \n",
       "3    -20.810318      -4.162064          2  \n",
       "4    -20.805621      -4.161124          2  \n",
       "5    -20.804152      -4.160830          2  \n",
       "6    -20.803939      -4.160788          2  \n",
       "7    -20.803749      -4.160750          2  \n",
       "8    -20.803858      -4.160772          2  \n",
       "9    -20.803917      -4.160783          2  \n",
       "10   -20.804043      -4.160809          2  \n",
       "11   -20.804344      -4.160869          2  \n",
       "12   -20.806651      -4.161330          2  \n",
       "13   -20.808876      -4.161775          2  \n",
       "14   -20.810943      -4.162189          2  \n",
       "15   -20.816348      -4.163270          2  \n",
       "16   -21.253404      -4.250681          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the number of zeros information to the summary information dataframe\n",
    "df_temp['Num_Zeros'] = np.array(num_zeros_list)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22596272, -0.        , -0.        , -0.        ],\n",
       "       [-0.        ,  2.74605582, -0.        , -0.        ],\n",
       "       [-0.        , -0.        ,  3.10477899, -0.        ],\n",
       "       [-0.        , -0.        , -0.        ,  1.44860969]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated precision matrix for the first lambda\n",
    "prec_mx_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.39660482, -0.03306993, -0.7758674 ,  0.        ],\n",
       "       [-0.03306993,  2.74694758, -0.        , -0.        ],\n",
       "       [-0.7758674 , -0.        ,  3.57628844, -0.24337161],\n",
       "       [ 0.        , -0.        , -0.24337161,  1.46744183]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated precision matrix for the second lambda\n",
    "prec_mx_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52069737, -0.17033761, -1.06283639,  0.11603294],\n",
       "       [-0.17033761,  2.78366128, -0.        , -0.14048774],\n",
       "       [-1.06283639, -0.        ,  3.98232618, -0.51782878],\n",
       "       [ 0.11603294, -0.14048774, -0.51782878,  1.52380577]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated precision matrix for the chosen lambda\n",
    "prec_mx_list[ind_lambda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
